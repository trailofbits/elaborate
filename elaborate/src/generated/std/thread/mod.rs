// This file was automatically generated by `elaborate`.
// https://github.com/trailofbits/elaborate

#[allow(unused_imports)]
use anyhow::Context;



pub trait BuilderContext {
/// Spawns a new scoped thread using the settings set through this `Builder`.
/// 
/// Unlike [`Scope::spawn`], this method yields an [`io::Result`] to
/// capture any failure to create the thread at the OS level.
/// 
/// [`io::Result`]: crate::io::Result
/// 
/// # Panics
/// 
/// Panics if a thread name was set and it contained null bytes.
/// 
/// # Example
/// 
/// ```
/// use std::thread;
/// 
/// let mut a = vec![1, 2, 3];
/// let mut x = 0;
/// 
/// thread::scope(|s| {
///     thread::Builder::new()
///         .name("first".to_string())
///         .spawn_scoped(s, ||
///     {
///         println!("hello from the {:?} scoped thread", thread::current().name());
///         // We can borrow `a` here.
///         dbg!(&a);
///     })
///     .unwrap();
///     thread::Builder::new()
///         .name("second".to_string())
///         .spawn_scoped(s, ||
///     {
///         println!("hello from the {:?} scoped thread", thread::current().name());
///         // We can even mutably borrow `x` here,
///         // because no other threads are using it.
///         x += a[0] + a[2];
///     })
///     .unwrap();
///     println!("hello from the main thread");
/// });
/// 
/// // After the scope, we can modify and access our variables again:
/// a.push(4);
/// assert_eq!(x, a.len());
/// ```
fn spawn_scoped_wc < 'scope , 'env , F , T > ( self , scope : & 'scope std :: thread :: Scope < 'scope , 'env > , f : F ) -> crate :: rewrite_output_type ! ( std :: io :: Result < std :: thread :: ScopedJoinHandle < 'scope , T > > ) where F : core :: ops :: FnOnce ( ) -> T + core :: marker :: Send + 'scope , T : core :: marker :: Send + 'scope;
/// Spawns a new thread by taking ownership of the `Builder`, and returns an
/// [`io::Result`] to its [`JoinHandle`].
/// 
/// The spawned thread may outlive the caller (unless the caller thread
/// is the main thread; the whole process is terminated when the main
/// thread finishes). The join handle can be used to block on
/// termination of the spawned thread, including recovering its panics.
/// 
/// For a more complete documentation see [`thread::spawn`][`spawn`].
/// 
/// # Errors
/// 
/// Unlike the [`spawn`] free function, this method yields an
/// [`io::Result`] to capture any failure to create the thread at
/// the OS level.
/// 
/// [`io::Result`]: crate::io::Result
/// 
/// # Panics
/// 
/// Panics if a thread name was set and it contained null bytes.
/// 
/// # Examples
/// 
/// ```
/// use std::thread;
/// 
/// let builder = thread::Builder::new();
/// 
/// let handler = builder.spawn(|| {
///     // thread code
/// }).unwrap();
/// 
/// handler.join().unwrap();
/// ```
fn spawn_wc < F , T > ( self , f : F ) -> crate :: rewrite_output_type ! ( std :: io :: Result < std :: thread :: JoinHandle < T > > ) where F : core :: ops :: FnOnce ( ) -> T + core :: marker :: Send + 'static , T : core :: marker :: Send + 'static;
/// Spawns a new thread without any lifetime restrictions by taking ownership
/// of the `Builder`, and returns an [`io::Result`] to its [`JoinHandle`].
/// 
/// The spawned thread may outlive the caller (unless the caller thread
/// is the main thread; the whole process is terminated when the main
/// thread finishes). The join handle can be used to block on
/// termination of the spawned thread, including recovering its panics.
/// 
/// This method is identical to [`thread::Builder::spawn`][`Builder::spawn`],
/// except for the relaxed lifetime bounds, which render it unsafe.
/// For a more complete documentation see [`thread::spawn`][`spawn`].
/// 
/// # Errors
/// 
/// Unlike the [`spawn`] free function, this method yields an
/// [`io::Result`] to capture any failure to create the thread at
/// the OS level.
/// 
/// # Panics
/// 
/// Panics if a thread name was set and it contained null bytes.
/// 
/// # Safety
/// 
/// The caller has to ensure that the spawned thread does not outlive any
/// references in the supplied thread closure and its return type.
/// This can be guaranteed in two ways:
/// 
/// - ensure that [`join`][`JoinHandle::join`] is called before any referenced
/// data is dropped
/// - use only types with `'static` lifetime bounds, i.e., those with no or only
/// `'static` references (both [`thread::Builder::spawn`][`Builder::spawn`]
/// and [`thread::spawn`][`spawn`] enforce this property statically)
/// 
/// # Examples
/// 
/// ```
/// use std::thread;
/// 
/// let builder = thread::Builder::new();
/// 
/// let x = 1;
/// let thread_x = &x;
/// 
/// let handler = unsafe {
///     builder.spawn_unchecked(move || {
///         println!("x = {}", *thread_x);
///     }).unwrap()
/// };
/// 
/// // caller has to ensure `join()` is called, otherwise
/// // it is possible to access freed memory if `x` gets
/// // dropped before the thread closure is executed!
/// handler.join().unwrap();
/// ```
/// 
/// [`io::Result`]: crate::io::Result
#[cfg(feature = "thread_spawn_unchecked")]
unsafe fn spawn_unchecked_wc < F , T > ( self , f : F ) -> crate :: rewrite_output_type ! ( std :: io :: Result < std :: thread :: JoinHandle < T > > ) where F : core :: ops :: FnOnce ( ) -> T + core :: marker :: Send , T : core :: marker :: Send;
}
impl BuilderContext for std :: thread :: Builder {
fn spawn_scoped_wc < 'scope , 'env , F , T > ( self , scope : & 'scope std :: thread :: Scope < 'scope , 'env > , f : F ) -> crate :: rewrite_output_type ! ( std :: io :: Result < std :: thread :: ScopedJoinHandle < 'scope , T > > ) where F : core :: ops :: FnOnce ( ) -> T + core :: marker :: Send + 'scope , T : core :: marker :: Send + 'scope {
    std :: thread :: Builder :: spawn_scoped(self, scope, f)
        .with_context(|| crate::call_failed!(Some(crate::CustomDebugMessage("value of type std::thread::Builder")), "spawn_scoped", scope, crate::CustomDebugMessage("value of type impl FnOnce")))
}
fn spawn_wc < F , T > ( self , f : F ) -> crate :: rewrite_output_type ! ( std :: io :: Result < std :: thread :: JoinHandle < T > > ) where F : core :: ops :: FnOnce ( ) -> T + core :: marker :: Send + 'static , T : core :: marker :: Send + 'static {
    std :: thread :: Builder :: spawn(self, f)
        .with_context(|| crate::call_failed!(Some(crate::CustomDebugMessage("value of type std::thread::Builder")), "spawn", crate::CustomDebugMessage("value of type impl FnOnce")))
}
#[cfg(feature = "thread_spawn_unchecked")]
unsafe fn spawn_unchecked_wc < F , T > ( self , f : F ) -> crate :: rewrite_output_type ! ( std :: io :: Result < std :: thread :: JoinHandle < T > > ) where F : core :: ops :: FnOnce ( ) -> T + core :: marker :: Send , T : core :: marker :: Send {
    unsafe { std :: thread :: Builder :: spawn_unchecked(self, f)
        .with_context(|| crate::call_failed!(Some(crate::CustomDebugMessage("value of type std::thread::Builder")), "spawn_unchecked", crate::CustomDebugMessage("value of type impl FnOnce"))) }
}
}
pub trait ThreadContext {
/// Gets the thread's name.
/// 
/// For more information about named threads, see
/// [this module-level documentation][naming-threads].
/// 
/// # Examples
/// 
/// Threads by default have no name specified:
/// 
/// ```
/// use std::thread;
/// 
/// let builder = thread::Builder::new();
/// 
/// let handler = builder.spawn(|| {
///     assert!(thread::current().name().is_none());
/// }).unwrap();
/// 
/// handler.join().unwrap();
/// ```
/// 
/// Thread with a specified name:
/// 
/// ```
/// use std::thread;
/// 
/// let builder = thread::Builder::new()
///     .name("foo".into());
/// 
/// let handler = builder.spawn(|| {
///     assert_eq!(thread::current().name(), Some("foo"))
/// }).unwrap();
/// 
/// handler.join().unwrap();
/// ```
/// 
/// [naming-threads]: ./index.html#naming-threads
fn name_wc ( & self ) -> crate :: rewrite_output_type ! ( core :: option :: Option < & str > );
}
impl ThreadContext for std :: thread :: Thread {
fn name_wc ( & self ) -> crate :: rewrite_output_type ! ( core :: option :: Option < & str > ) {
    std :: thread :: Thread :: name(self)
        .with_context(|| crate::call_failed!(Some(self), "name"))
}
}


/// Returns an estimate of the default amount of parallelism a program should use.
/// 
/// Parallelism is a resource. A given machine provides a certain capacity for
/// parallelism, i.e., a bound on the number of computations it can perform
/// simultaneously. This number often corresponds to the amount of CPUs a
/// computer has, but it may diverge in various cases.
/// 
/// Host environments such as VMs or container orchestrators may want to
/// restrict the amount of parallelism made available to programs in them. This
/// is often done to limit the potential impact of (unintentionally)
/// resource-intensive programs on other programs running on the same machine.
/// 
/// # Limitations
/// 
/// The purpose of this API is to provide an easy and portable way to query
/// the default amount of parallelism the program should use. Among other things it
/// does not expose information on NUMA regions, does not account for
/// differences in (co)processor capabilities or current system load,
/// and will not modify the program's global state in order to more accurately
/// query the amount of available parallelism.
/// 
/// Where both fixed steady-state and burst limits are available the steady-state
/// capacity will be used to ensure more predictable latencies.
/// 
/// Resource limits can be changed during the runtime of a program, therefore the value is
/// not cached and instead recomputed every time this function is called. It should not be
/// called from hot code.
/// 
/// The value returned by this function should be considered a simplified
/// approximation of the actual amount of parallelism available at any given
/// time. To get a more detailed or precise overview of the amount of
/// parallelism available to the program, you may wish to use
/// platform-specific APIs as well. The following platform limitations currently
/// apply to `available_parallelism`:
/// 
/// On Windows:
/// - It may undercount the amount of parallelism available on systems with more
///   than 64 logical CPUs. However, programs typically need specific support to
///   take advantage of more than 64 logical CPUs, and in the absence of such
///   support, the number returned by this function accurately reflects the
///   number of logical CPUs the program can use by default.
/// - It may overcount the amount of parallelism available on systems limited by
///   process-wide affinity masks, or job object limitations.
/// 
/// On Linux:
/// - It may overcount the amount of parallelism available when limited by a
///   process-wide affinity mask or cgroup quotas and `sched_getaffinity()` or cgroup fs can't be
///   queried, e.g. due to sandboxing.
/// - It may undercount the amount of parallelism if the current thread's affinity mask
///   does not reflect the process' cpuset, e.g. due to pinned threads.
/// - If the process is in a cgroup v1 cpu controller, this may need to
///   scan mountpoints to find the corresponding cgroup v1 controller,
///   which may take time on systems with large numbers of mountpoints.
///   (This does not apply to cgroup v2, or to processes not in a
///   cgroup.)
/// 
/// On all targets:
/// - It may overcount the amount of parallelism available when running in a VM
/// with CPU usage limits (e.g. an overcommitted host).
/// 
/// # Errors
/// 
/// This function will, but is not limited to, return errors in the following
/// cases:
/// 
/// - If the amount of parallelism is not known for the target platform.
/// - If the program lacks permission to query the amount of parallelism made
///   available to it.
/// 
/// # Examples
/// 
/// ```
/// # #![allow(dead_code)]
/// use std::{io, thread};
/// 
/// fn main() -> io::Result<()> {
///     let count = thread::available_parallelism()?.get();
///     assert!(count >= 1_usize);
///     Ok(())
/// }
/// ```
pub fn available_parallelism_wc ( ) -> crate :: rewrite_output_type ! ( std :: io :: Result < core :: num :: NonZero < usize > > ) {
    std :: thread :: available_parallelism()
        .with_context(|| crate::call_failed!(None::<()>, "std::thread::available_parallelism"))
}
